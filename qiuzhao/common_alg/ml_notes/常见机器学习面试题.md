## 机器学习常见面试题

+ 有监督和无监督学习的区别
```
有监督学习：对具有标记的样本数据进行学习，以尽可能对训练样本集外的数据进行分类预测(LR, SVM, BP, RF, GBRT)
非监督学习：对未标记的样本进行训练学习，并发现这些样本中的结构只是（KMeans, DL）
```
+ 过拟合

```
模型 拟合训练数据过头了，导致训练误差很小，但是测试误差非常大

产生原因：
	参数太多，导致模型的复杂度上升，容易过拟合
    权值学习迭代次数足够多，拟合了训练数据中的噪声和训练数据中没有代表性的特征

解决方法：
	交叉验证
    减少特征
    正则化(重要)
    权值衰减
    验证数据
```

+ 泛华能力
```
泛华能力是模型对未知数据的预测能力
```
    
+ 生成模型和判别模型

```
生成模型：由数据学习联合概率分布P（X,Y）,然后求出条件概率分布P(Y/X)作为预测的模型，即生成模型。
P(Y|X) = P(X, Y)/P(X) 生成模型可以还原联合概率分布p(X,Y),并且有较快的学习收敛速率，还可以用于隐变量的学习。(朴素贝叶斯， 马尔科夫)

判别模型：由数据直接学习决策函数Y=f(X)或者条件概率分布P(Y|X)作为预测的模型（逻辑回归，SVM...）

```

+ 线性分类器与非线性分类器的区别以及优点

```
如果模型是参数的线性函数，并且存在线性分类面，那么就是线性可分的
常见的线性分类器：LR, 贝叶斯分类，单层感知机， 线性回归
常见的非线性分类：决策树， RF, GBDT, 多层感知机
SVM两种都有（看线性核还是高斯核）

线性分类器速度快，编程方便，但是可能拟合效果不会很好
非线性分类器编程复杂，但是效果拟合能力强
```

+ 特征比数据量还大时，选择什么样的分类器
```
线性分类器，因为维度高的时候，数据一般在维度空间里面会比较稀疏，很有可能线性可分
```

+ 对于维度极低的特征，你是选择线性还是非线性

```
非线性分类器，因为低维空间可能很多特征都跑到一起了，导致线性不可分
```

+ 病态问题

```
训练完的模型测试样本稍作修改就会得到差别很大的结果，就是病态问题
```

+ 正则化
```
L1正则化是指权值向量w中各元素的绝对值之和
L2正则化是指权值向量w中个元素的平方和然后再求平方根

作用：
   L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择
   L2正则化可以防止模型过拟合，一定程度上L1也可以防止过拟合

```

+ 特征向量的归一化方法

```
1.线性函数转换 y = (x - min)/(max - min)
2.对数函数转换 y = log10(x)
3.反余切函数转换 y = arctan(x) * 2/pi
4.减去均值，乘以方差 y = (x - means)/variance
```
